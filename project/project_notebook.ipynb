{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scaleapi\n",
    "import json\n",
    "from datetime import datetime\n",
    "import math\n",
    "import sys\n",
    "from scaleapi.tasks import TaskReviewStatus, TaskStatus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_api_key():\n",
    "    # Input:\n",
    "    #   Nothing\n",
    "    # Returns:\n",
    "    #   api_key \n",
    "    path = './key/key.json'\n",
    "    with open(path) as f:\n",
    "        return json.load(f)['api_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_projects(client):\n",
    "    # Input:\n",
    "    #   client : scaleSDK client object\n",
    "    # Returns:\n",
    "    #   project_map : dict of projects {num : project_name}\n",
    "    counter = 0\n",
    "    project_map = {}\n",
    "    projects = client.projects()\n",
    "    for project in projects:\n",
    "        counter += 1\n",
    "        project_map[str(counter)] = project.name\n",
    "        print(f'{counter} | {project.name} | {project.type}')\n",
    "    return project_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_project(project_map):\n",
    "    # Input: \n",
    "    #   project_map dict of all projects\n",
    "    # Returns: \n",
    "    #   project_name string\n",
    "    print(\"------------------------------------------\")\n",
    "    print(\"Which project would you like to test?\")\n",
    "    print(\"Please input a number from the list above: \")\n",
    "    project_num = input()\n",
    "    if(project_num in project_map.keys()):\n",
    "        project_name = project_map[project_num]\n",
    "        print(\"Project: \"+project_name+\" selected.\")\n",
    "        return project_name\n",
    "    else:\n",
    "        print(\"Please input a valid project number.\")\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_tasks(client, project_name=\"Traffic Sign Detection\"):\n",
    "    # Input:\n",
    "    #   client : scaleSDK client object \n",
    "    #   project_name : project name string \n",
    "    # Returns:\n",
    "    #   task_ids : list of task ids(strings).\n",
    "    #   num_tasks : number of tasks total in the project\n",
    "    # Runtime: \n",
    "    #   O(n): n = number of tasks\n",
    "    tasks = client.get_tasks(\n",
    "        project_name = project_name\n",
    "    )\n",
    "    num_tasks=0\n",
    "    task_ids = []\n",
    "    for task in tasks:\n",
    "        num_tasks = num_tasks+1\n",
    "        task_ids.append(task.task_id)\n",
    "\n",
    "    # For retrieving results as a Task list\n",
    "    task_list = list(tasks)\n",
    "    print(str(num_tasks)+\" tasks retrieved\")\n",
    "    return task_ids, num_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task(client, task_id='5f127f6f26831d0010e985e5'):\n",
    "    # Input: \n",
    "    #   task_id : task id string\n",
    "    # Returns:\n",
    "    #   task_id : task id string\n",
    "    #   task    : task information dict\n",
    "    # Runtime: \n",
    "    #   O(1)\n",
    "\n",
    "    task = client.get_task(task_id)\n",
    "    print(task.status)  \n",
    "    # Task status (\"pending\", \"completed\", \"error\", \"canceled\")\n",
    "    if(task.status == \"completed\"):\n",
    "        return task_id, task, True\n",
    "    else: \n",
    "        print(\"Task not complete.\")\n",
    "        print(\"------------------\")\n",
    "        return -1, {}, False\n",
    "\n",
    "\n",
    "def get_num_unique_labels(task):\n",
    "    # Input: \n",
    "    #   task : task information dict\n",
    "    # Returns:\n",
    "    #   num_unique_labels : number of unique label types in a task int\n",
    "    # Runtime: \n",
    "    #   O(m) number of labels in a given task\n",
    "    #   NOTE: pd.unique is quite well optimized\n",
    "    \n",
    "    tasks_df = pd.DataFrame(task.response['annotations'])\n",
    "    num_unique_labels = len(pd.unique(tasks_df['label']))  # O(m)\n",
    "    print(\"Number of unique label types: \"+str(num_unique_labels))\n",
    "    return num_unique_labels\n",
    "\n",
    "def create_dict(task_id, task, num_unique_labels):\n",
    "    # Input:\n",
    "    #   task_id : task_id string\n",
    "    #   task    : task information dict\n",
    "    #   num_unique_lables : number of unique label types in a task int\n",
    "    # Returns:\n",
    "    #   task_id : task_id string\n",
    "    #   num_dict : dictionary \n",
    "    # Runtime: \n",
    "    #   O(1)\n",
    "    num_dict = {\n",
    "            \"task_id\" : task_id,\n",
    "            \"task\" : task,\n",
    "            \"num_unique_labels\": num_unique_labels\n",
    "    }\n",
    "    \n",
    "    return task_id,num_dict\n",
    "\n",
    "\n",
    "# Average here can be changed to median, anything really to improve this tool\n",
    "def create_output_dict(task_id, task, num_unique_labels, limit):\n",
    "    # Input:\n",
    "    #   task_id : task_id string\n",
    "    #   task    : task information dict\n",
    "    #   num_unique_lables : number of unique label types in a task int\n",
    "    #   limit : in this current implementation this limit is the average\n",
    "    # Returns:\n",
    "    #   output_dict : dictionary that contains flag information for a given task\n",
    "    # Runtime: \n",
    "    #   O(1)\n",
    "    \n",
    "    if(num_unique_labels < limit):\n",
    "        flag = True\n",
    "    else:\n",
    "        flag = False\n",
    "    # NOTE a 'True' flag means that a flag should be triggered. \n",
    "    output_dict = {\n",
    "            \"task_id\" : task_id,\n",
    "            \"average_unique_labels\" : limit,\n",
    "            \"num_unique_labels\": num_unique_labels,\n",
    "            \"flag\": flag\n",
    "    }\n",
    "    return output_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_output(output_dict, project_name):\n",
    "    # Input: \n",
    "    #   output_dict: dictionary to be saved as json file\n",
    "    # Returns:\n",
    "    #   NOTHING - saves json file to output/ folder\n",
    "\n",
    "    # Makes new output folder\n",
    "    path = os.getcwd()\n",
    "    newpath = path+\"/output/\"\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "\n",
    "    # Makes output json file\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    json_object = json.dumps(output_dict, indent = 4) \n",
    "    print(json_object)\n",
    "    filename =  \"./output/variety_flags_\"+project_name+\".json\"\n",
    "    with open(filename, \"w\") as outfile:\n",
    "        json.dump(output_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Overall complexity : O(N*M)\n",
    "#   n = number of tasks\n",
    "#   m = number of labels per task\n",
    "def main():\n",
    "    api_key= get_api_key()# Live one\n",
    "    client = scaleapi.ScaleClient(api_key)\n",
    "    \n",
    "    project_map = list_projects(client)\n",
    "    project_name = select_project(project_map)\n",
    "\n",
    "    unique_labels_dict = {}\n",
    "    num_unique_labels_sum = 0\n",
    "    tasks, num_tasks = list_tasks(client=client, project_name=project_name)  # O(n) : n = number of tasks\n",
    "\n",
    "    # Many ways to optimize here - either do it with moving average, median number of label types or another method \n",
    "    # like assuming normal distribution and find exptected number of label types\n",
    "    # Complexity : O(n*m) where m<n \n",
    "    #               n = number of tasks\n",
    "    #               m = number of labels per task \n",
    "    for task_id in tasks:\n",
    "        task_id, task, done = get_task(client=client,task_id=task_id)\n",
    "        if(not done):\n",
    "            print(\"Please wait for all tasks to complete before running QC.\")\n",
    "            return -1\n",
    "        num_unique_labels = get_num_unique_labels(task=task)  # Runtime : O(m)\n",
    "        num_unique_labels_sum = num_unique_labels_sum + num_unique_labels\n",
    "        task_id, num_dict = create_dict(task_id=task_id,task=task,num_unique_labels=num_unique_labels)\n",
    "        unique_labels_dict[task_id] = num_dict\n",
    "    if(num_tasks!=0):\n",
    "        average_unique_labels = math.ceil(num_unique_labels_sum/num_tasks)\n",
    "    else:\n",
    "        average_unique_labels = 0 \n",
    "    print(\"Average unique labels: \" +str(average_unique_labels))\n",
    "    \n",
    "    output_dict = {}\n",
    "    # Complexity : O(n) where n = number of tasks\n",
    "    for task_id in tasks:\n",
    "        output_dict[task_id] = create_output_dict(\n",
    "            task_id = unique_labels_dict[task_id]['task_id'], \n",
    "            task=unique_labels_dict[task_id]['task'],            \n",
    "            num_unique_labels=unique_labels_dict[task_id]['num_unique_labels'], \n",
    "            limit=average_unique_labels\n",
    "        )\n",
    "    # print(output_dict.keys())\n",
    "    print(\"-----------------------------------------------------------\")\n",
    "    print(\"Output:\")\n",
    "    print(\"A 'True' status indicates that a task needs to be reviewed.\")\n",
    "    # Complexity : O(n) where n = number of tasks\n",
    "    # This is also just to make pretty output and is not necessary for json out\n",
    "    for task_id in tasks:\n",
    "        print(\"\\t\"+str(task_id)+\" : \"+str(output_dict[task_id]['flag']))\n",
    "    make_output(output_dict, project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 | Traffic Sign Detection | annotation\n",
      "2 | sunshineTest | annotation\n",
      "3 | sunshineTestTwo | annotation\n",
      "4 | Scale AI_default_imageannotation | imageannotation\n",
      "5 | kitten_labeling | imageannotation\n",
      "6 | try | imageannotation\n",
      "7 | Traffic_Light_Detection | imageannotation\n",
      "8 | Test Project | imageannotation\n",
      "9 | Test_Project5 | imageannotation\n",
      "10 | Traffic Light Detection | imageannotation\n",
      "11 | Traffic Light Detection 2 | imageannotation\n",
      "12 | AV Template Project | imageannotation\n",
      "13 | Test1234 | imageannotation\n",
      "14 | Kitti Data Annotation | lidarannotation\n",
      "15 | Scale AI_default_lidarannotation | lidarannotation\n",
      "16 | Scale AI_default_segmentannotation | segmentannotation\n",
      "------------------------------------------\n",
      "Which project would you like to test?\n",
      "Please input a number from the list above: \n",
      "Project: Traffic Sign Detection selected.\n",
      "8 tasks retrieved\n",
      "completed\n",
      "Number of unique label types: 4\n",
      "completed\n",
      "Number of unique label types: 4\n",
      "completed\n",
      "Number of unique label types: 2\n",
      "completed\n",
      "Number of unique label types: 4\n",
      "completed\n",
      "Number of unique label types: 4\n",
      "completed\n",
      "Number of unique label types: 5\n",
      "completed\n",
      "Number of unique label types: 4\n",
      "completed\n",
      "Number of unique label types: 4\n",
      "Average unique labels: 4\n",
      "-----------------------------------------------------------\n",
      "Output:\n",
      "A 'True' status indicates that a task needs to be reviewed.\n",
      "\t5f127f6f26831d0010e985e5 : False\n",
      "\t5f127f6c3a6b1000172320ad : False\n",
      "\t5f127f699740b80017f9b170 : True\n",
      "\t5f127f671ab28b001762c204 : False\n",
      "\t5f127f643a6b1000172320a5 : False\n",
      "\t5f127f5f3a6b100017232099 : False\n",
      "\t5f127f5ab1cb1300109e4ffc : False\n",
      "\t5f127f55fdc4150010e37244 : False\n",
      "{\n",
      "    \"5f127f6f26831d0010e985e5\": {\n",
      "        \"task_id\": \"5f127f6f26831d0010e985e5\",\n",
      "        \"average_unique_labels\": 4,\n",
      "        \"num_unique_labels\": 4,\n",
      "        \"flag\": false\n",
      "    },\n",
      "    \"5f127f6c3a6b1000172320ad\": {\n",
      "        \"task_id\": \"5f127f6c3a6b1000172320ad\",\n",
      "        \"average_unique_labels\": 4,\n",
      "        \"num_unique_labels\": 4,\n",
      "        \"flag\": false\n",
      "    },\n",
      "    \"5f127f699740b80017f9b170\": {\n",
      "        \"task_id\": \"5f127f699740b80017f9b170\",\n",
      "        \"average_unique_labels\": 4,\n",
      "        \"num_unique_labels\": 2,\n",
      "        \"flag\": true\n",
      "    },\n",
      "    \"5f127f671ab28b001762c204\": {\n",
      "        \"task_id\": \"5f127f671ab28b001762c204\",\n",
      "        \"average_unique_labels\": 4,\n",
      "        \"num_unique_labels\": 4,\n",
      "        \"flag\": false\n",
      "    },\n",
      "    \"5f127f643a6b1000172320a5\": {\n",
      "        \"task_id\": \"5f127f643a6b1000172320a5\",\n",
      "        \"average_unique_labels\": 4,\n",
      "        \"num_unique_labels\": 4,\n",
      "        \"flag\": false\n",
      "    },\n",
      "    \"5f127f5f3a6b100017232099\": {\n",
      "        \"task_id\": \"5f127f5f3a6b100017232099\",\n",
      "        \"average_unique_labels\": 4,\n",
      "        \"num_unique_labels\": 5,\n",
      "        \"flag\": false\n",
      "    },\n",
      "    \"5f127f5ab1cb1300109e4ffc\": {\n",
      "        \"task_id\": \"5f127f5ab1cb1300109e4ffc\",\n",
      "        \"average_unique_labels\": 4,\n",
      "        \"num_unique_labels\": 4,\n",
      "        \"flag\": false\n",
      "    },\n",
      "    \"5f127f55fdc4150010e37244\": {\n",
      "        \"task_id\": \"5f127f55fdc4150010e37244\",\n",
      "        \"average_unique_labels\": 4,\n",
      "        \"num_unique_labels\": 4,\n",
      "        \"flag\": false\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "b8bdd4e700647ba2b08c59e5df8b7da1dcf50a218bcd4c1bcd9b3dc92e8788e5"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}